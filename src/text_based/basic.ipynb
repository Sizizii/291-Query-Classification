{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(path):\n",
    "  with open(path) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "  plain_sql = [item['sql'] for item in json_data]\n",
    "  plain_sql = [sql.lower() for sql in plain_sql]\n",
    "\n",
    "  # split data into tokens\n",
    "\n",
    "  pattern = r'[\\s()\\-,:;]'\n",
    "  string_literal_pattern = r\"'([^']*)'\"\n",
    "  placeholder = \"<string>\"\n",
    "  \n",
    "  # replace content inside single quotes by <string>\n",
    "  plain_sql_ph = [re.sub(string_literal_pattern, placeholder, sql) for sql in   plain_sql]\n",
    "  \n",
    "  # split the statements with placeholder\n",
    "  tokenized_sql = [re.split(pattern, sql) for sql in plain_sql_ph]\n",
    "  \n",
    "  # remove empty tokens\n",
    "  tokenized_sql = [token for token in tokenized_sql if token]\n",
    "  \n",
    "  # replace numbers by placeholder\n",
    "  for sql in tokenized_sql:\n",
    "      for i, token in enumerate(sql):\n",
    "          # if re.match(r'^[\\'\\\"].*[\\'\\\"]$', token):  # Check if token is a   string literal\n",
    "          #     sql[i] = '<string>'\n",
    "          if re.match(r'^[0-9]+(\\.[0-9]+)?$', token):  # Check if token is a  number\n",
    "              sql[i] = '<number>'\n",
    "  \n",
    "  # remove empty tokens\n",
    "  for i, sql in enumerate(tokenized_sql):\n",
    "      tokenized_sql[i] = [token for token in tokenized_sql[i] if token]\n",
    "\n",
    "    # build the vocab\n",
    "  vocab_set = set()\n",
    "  for sql in tokenized_sql:\n",
    "      vocab_set.update(sql)\n",
    "\n",
    "  vocab_dict = {word: idx for idx, word in enumerate(vocab_set)}\n",
    "\n",
    "  # get the runtimes\n",
    "  runtime = [item['runtime_ms'] for item in json_data]\n",
    "  runtime = np.array(runtime)\n",
    "\n",
    "  # classify the runtimes, label 0 for runtime <=3000ms, 1 for runtime >3000ms\n",
    "  label = np.where(runtime > 3000, 1, 0)\n",
    "\n",
    "  return vocab_set, plain_sql_ph, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set_15k, plain_sql_ph_15k, label_15k = tokenize(\"../datasets/plain_text/plain_statement.json\")\n",
    "vocab_set_5k, plain_sql_ph_5k, label_5k = tokenize(\"../datasets/plain_text/plain_statement_5000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_set)\n",
    "cv_mat_15k = vectorizer.fit_transform(plain_sql_ph_15k)\n",
    "cv_mat_5k = vectorizer.fit_transform(plain_sql_ph_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_mat_15k = tfidf_vectorizer.fit_transform(plain_sql_ph_15k)\n",
    "tfidf_mat_15k = tfidf_mat_15k.toarray()\n",
    "\n",
    "tfidf_mat_5k = tfidf_vectorizer.fit_transform(plain_sql_ph_5k)\n",
    "tfidf_mat_5k = tfidf_mat_5k.toarray()\n",
    "# tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(cv_mat, tfidf_mat, label):\n",
    "  X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_mat, label, test_size=0.2, random_state=seed)\n",
    "\n",
    "  X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(cv_mat, label, test_size=0.2, random_state=seed)\n",
    "\n",
    "  \n",
    "  def experiment_cv(model):\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred = model.predict(X_test_cv)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "\n",
    "    precision_positive = precision_score(y_test_cv, y_pred, pos_label=1)\n",
    "    recall_positive = recall_score(y_test_cv, y_pred, pos_label=1)\n",
    "    precision_negative = precision_score(y_test_cv, y_pred, pos_label=0)\n",
    "    recall_negative = recall_score(y_test_cv, y_pred, pos_label=0)\n",
    "\n",
    "    return accuracy, precision_positive, recall_positive, precision_negative, recall_negative\n",
    "\n",
    "  def experiment_tfidf(model):\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_tfidf, y_pred)\n",
    "\n",
    "    precision_positive = precision_score(y_test_tfidf, y_pred, pos_label=1)\n",
    "    recall_positive = recall_score(y_test_tfidf, y_pred, pos_label=1)\n",
    "    precision_negative = precision_score(y_test_tfidf, y_pred, pos_label=0)\n",
    "    recall_negative = recall_score(y_test_tfidf, y_pred, pos_label=0)\n",
    "\n",
    "    return accuracy, precision_positive, recall_positive, precision_negative, recall_negative\n",
    "  \n",
    "  models = {\"LR\": LogisticRegression(max_iter=1000), \"XGB\": xgb.XGBClassifier(), \"RF\": RandomForestClassifier(n_estimators=100, random_state=seed)}\n",
    "\n",
    "  result_cv = dict()\n",
    "  result_tfidf = dict()\n",
    "\n",
    "  for key in models:\n",
    "    model = models[key]\n",
    "\n",
    "    result_cv[key] = experiment_cv(model)\n",
    "    print(\"Completed training of model {key} for BoW\")\n",
    "    result_tfidf[key] = experiment_tfidf(model)\n",
    "    print(\"Completed training of model {key} for TF-IDF\")\n",
    "\n",
    "  result_cv[\"SVM\"] = experiment_cv(SVC())\n",
    "  print(\"Completed training of model SVM for BoW\")\n",
    "\n",
    "  return result_cv, result_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training of model {key} for BoW\n",
      "Completed training of model {key} for TF-IDF\n",
      "Completed training of model {key} for BoW\n",
      "Completed training of model {key} for TF-IDF\n",
      "Completed training of model {key} for BoW\n",
      "Completed training of model {key} for TF-IDF\n",
      "Completed training of model SVM for BoW\n",
      "Completed training of model {key} for BoW\n",
      "Completed training of model {key} for TF-IDF\n",
      "Completed training of model {key} for BoW\n",
      "Completed training of model {key} for TF-IDF\n",
      "Completed training of model {key} for BoW\n",
      "Completed training of model {key} for TF-IDF\n",
      "Completed training of model SVM for BoW\n"
     ]
    }
   ],
   "source": [
    "r_cv_5k, r_tfidf_5k = run_exp(cv_mat_5k, tfidf_mat_5k, label_5k)\n",
    "r_cv_15k, r_tfidf_15k = run_exp(cv_mat_15k, tfidf_mat_15k, label_15k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of BoW - 5k\n",
      "LR: (0.711, 0.5682539682539682, 0.5391566265060241, 0.7766423357664234, 0.7964071856287425)\n",
      "XGB: (0.71, 0.5734265734265734, 0.4939759036144578, 0.7647058823529411, 0.8173652694610778)\n",
      "RF: (0.692, 0.54, 0.4879518072289157, 0.7571428571428571, 0.7934131736526946)\n",
      "SVM: (0.731, 0.64, 0.43373493975903615, 0.7574193548387097, 0.8787425149700598)\n",
      "Results of BoW - 15k\n",
      "LR: (0.7146866230121609, 0.5768463073852296, 0.42066957787481807, 0.7568723274282224, 0.853893866299104)\n",
      "XGB: (0.7240411599625819, 0.5987780040733197, 0.4279475982532751, 0.761384335154827, 0.8642315644383184)\n",
      "RF: (0.7226379794200187, 0.5967078189300411, 0.42212518195050946, 0.7596852300242131, 0.864920744314266)\n",
      "SVM: (0.7188961646398503, 0.6452702702702703, 0.2780203784570597, 0.7307274701411509, 0.9276361130254996)\n"
     ]
    }
   ],
   "source": [
    "print(\"Results of BoW - 5k\")\n",
    "for key, value in r_cv_5k.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"Results of BoW - 15k\")\n",
    "for key, value in r_cv_15k.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of TF-IDF - 5k\n",
      "LR: (0.796, 0.6927710843373494, 0.6927710843373494, 0.8473053892215568, 0.8473053892215568)\n",
      "XGB: (0.786, 0.6766467065868264, 0.6807228915662651, 0.8408408408408409, 0.8383233532934131)\n",
      "RF: (0.794, 0.688622754491018, 0.6927710843373494, 0.8468468468468469, 0.844311377245509)\n",
      "Results of TF-IDF - 15k\n",
      "LR: (0.8016838166510758, 0.7138211382113822, 0.6390101892285298, 0.8371634931057124, 0.8787043418332184)\n",
      "XGB: (0.7792329279700655, 0.6616541353383458, 0.6404657933042213, 0.8323150033944331, 0.844934527911785)\n",
      "RF: (0.7834424695977549, 0.6812297734627831, 0.6128093158660844, 0.825, 0.8642315644383184)\n"
     ]
    }
   ],
   "source": [
    "print(\"Results of TF-IDF - 5k\")\n",
    "for key, value in r_tfidf_5k.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"Results of TF-IDF - 15k\")\n",
    "for key, value in r_tfidf_15k.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PyTorch Embedding\n",
    "\n",
    "# define embedding layer\n",
    "\n",
    "# vocab_size = len(vocab_dict)\n",
    "# embedding_dim = 10\n",
    "# embedding = nn.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokens to indices for each sample\n",
    "# indices = [torch.LongTensor([vocab_dict[token] for token in sql]) for sql in tokenized_sql]\n",
    "\n",
    "# X_torch = []\n",
    "\n",
    "# for index in indices:\n",
    "#     emb = embedding(index)\n",
    "#     sum = torch.sum(emb, dim=0)\n",
    "#     X_torch.append(sum.tolist())\n",
    "\n",
    "# X_torch = np.array(X_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
